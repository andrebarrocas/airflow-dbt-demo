x-airflow-common: &airflow-common
  image: custom-airflow-dbt
  environment: &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__WEBSERVER__SECRET_KEY: 'this-is-a-test-key-do-not-use-in-production'
  volumes:
    - ./dags:/opt/airflow/dags
    - ./dbt_project:/opt/airflow/dbt_project
    - ./setup:/opt/airflow/setup

services:
  postgres:
    image: postgres:13
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5

  airflow-init:
    <<: *airflow-common
    depends_on:
      postgres:
        condition: service_healthy
    command: >
      bash -c '
      airflow db init &&
      airflow users create --username airflow --password airflow --firstname Anonymous --lastname Admin --role Admin --email admin@example.com &&
      python /opt/airflow/setup/init_connections.py
      '

  airflow-webserver:
    <<: *airflow-common
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    ports:
      - "8080:8080"
    command: webserver
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  airflow-scheduler:
    <<: *airflow-common
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    command: scheduler 